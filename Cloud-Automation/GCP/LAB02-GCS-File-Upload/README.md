# GCP LAB02 - Automate File Upload to Google Cloud Storage (GCS) with Python

In this lab, you'll use Python and the `google-cloud-storage` library to upload files to a Google Cloud Storage (GCS) bucket â€” one of the most common automation tasks in cloud environments.

---

## ğŸ¯ Objectives

By the end of this lab, you will:
- Connect to GCS using service account authentication
- Upload a file to a GCS bucket programmatically
- List objects in a bucket with the Python SDK
- Understand blob objects, metadata, and GCS naming conventions

---

## ğŸ§° Prerequisites

- Google Cloud account with an active project
- GCS bucket already created in your project
- Service account with Storage Admin role (roles/storage.admin)
- Service account key file (JSON) downloaded to your local machine
- Python 3.8 or higher installed

---

## ğŸ“ Lab Files

```
Cloud-Automation/GCP/LAB02-GCS-File-Upload/
â”œâ”€â”€ upload_file.py        # The main Python script (with TODOs)
â”œâ”€â”€ sample.txt            # Sample file to upload
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ solutions.md          # Solutions to the TODOs
â””â”€â”€ README.md             # This file
```

---

## ğŸš€ Getting Started

### 1. Set up authentication

Before running the script, you need to authenticate with Google Cloud:

```bash
# Set the environment variable to point to your service account key file
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your-service-account.json"
```

### 2. Navigate to the lab folder

```bash
cd Cloud-Automation/GCP/LAB02-GCS-File-Upload/
```

### 3. Create and activate a virtual environment

```bash
# Create a virtual environment
python -m venv .venv

# Activate the virtual environment
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate
```

### 4. Install dependencies

```bash
pip install -r requirements.txt
```

---

## âœï¸ Your Task

In this lab, you will complete the TODOs in the `upload_file.py` script to:

1. Initialize the Google Cloud Storage client
2. Create a reference to your GCS bucket
3. Create a blob object for the destination file
4. Upload the file to GCS
5. List all objects in the bucket
6. Optional: Explore blob metadata and properties

The script already contains:
- Argument parsing for customizing upload parameters
- Error handling and logging
- A sample file (`sample.txt`) for testing your implementation

Your job is to fill in the missing implementation details marked with `TODO` comments.

### Running the script

Once you've completed the TODOs, run your script with your bucket name:

```bash
python upload_file.py --bucket=your-gcs-bucket-name
```

To also list all files in the bucket after upload:

```bash
python upload_file.py --bucket=your-gcs-bucket-name --list
```

---

## ğŸ§ª Validation Checklist

Ensure your implementation:

âœ… Successfully authenticates with GCS  
âœ… Uploads the sample file to your bucket  
âœ… Lists all objects in the bucket when the `--list` flag is used  
âœ… Handles errors appropriately  
âœ… Shows the public URL for the uploaded file  

You can verify your upload in the Google Cloud Console or with the gsutil command:

```bash
gsutil ls gs://your-gcs-bucket-name/
```

---

## ğŸ§¹ Cleanup

To avoid incurring storage charges, delete the uploaded file when you're done:

```bash
gsutil rm gs://your-gcs-bucket-name/sample.txt
```

---

## ğŸ’¬ What's Next?

After completing this lab, proceed to [GCP LAB03 - IAM Service Account Creation](../LAB03-IAM-Service-Account-Creation/) to learn how to programmatically manage IAM service accounts and access controls in GCP.

---

## ğŸ™ Acknowledgments

Google Cloud Storage is an essential component for storing and serving files at scale. Mastering it unlocks endless automation workflows from web hosting to data lakes.

Happy cloud automating! ğŸ“‚â˜ï¸ğŸ